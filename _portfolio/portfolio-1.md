---
title: "1.Demystifying Attention: Building Core Mechanisms of Transformers in PyTorch "
excerpt: "A from-scratch PyTorch implementation of core transformer components including self-attention, masked attention, and multi-head attention following the seminal *Attention Is All You Need* paper.<br/><img src='/images/port_self_attention_vs_mulihead.png'>"
collection: portfolio
order: 1
---

NLP â€¢ Deep Learning â€¢ Interpretability â€¢ PyTorch
[ðŸ”— GitHub Repo](https://github.com/Tahsinmullick/coding_attention_transformer_pytorch)

Implemented self-attention, masked attention, and multi-head attention from scratch to demystify the mathematical core of transformer architectures.

Built a functional encoderâ€“decoder pipeline following Attention Is All You Need to strengthen low-level understanding important for alignment and safety research.

Designed clean, interpretable code to help expose matrix operations at each computation step.
